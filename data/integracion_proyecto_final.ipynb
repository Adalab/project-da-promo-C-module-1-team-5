{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos Base de datos #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQLCursor: CREATE DATABASE IF NOT EXISTS Project_1\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "cnx = mysql.connector.connect(user='root', password='AlumnaAdalab',\n",
    "                              host='127.0.0.1')\n",
    "\n",
    "\n",
    "mycursor = cnx.cursor()\n",
    "try:\n",
    "    mycursor.execute(\"CREATE DATABASE IF NOT EXISTS Project_1\")\n",
    "    print(mycursor)\n",
    "except mysql.connector.Error as err:\n",
    "    print(err)\n",
    "    print(\"Error Code:\", err.errno)\n",
    "    print(\"SQLSTATE\", err.sqlstate)\n",
    "    print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos tablas #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una funcion para crear la tabla correspondiente a cada extension de archivo, dentro de la Base de Datos Project_1\n",
    "\n",
    "def creacion_tablas (query_tablas):\n",
    "    \n",
    "    cnx = mysql.connector.connect(user='root', password='AlumnaAdalab',\n",
    "                              host='127.0.0.1', database='Project_1')\n",
    "\n",
    "\n",
    "    mycursor = cnx.cursor()\n",
    "    try:\n",
    "        mycursor.execute(query_tablas)\n",
    "        cnx.commit()\n",
    "        print(mycursor)\n",
    "    \n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "        print(\"Error Code:\", err.errno)\n",
    "        print(\"SQLSTATE\", err.sqlstate)\n",
    "        print(\"Message\", err.msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos query de creacion de tablas sql:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_sql = '''CREATE TABLE IF NOT EXISTS data_sql (\n",
    "index_sql INT NOT NULL PRIMARY KEY , \n",
    "q10_part_1 VARCHAR (55), \n",
    "q10_part_2 VARCHAR (55), \n",
    "q10_part_3 VARCHAR (55), \n",
    "q10_part_4 VARCHAR (55), \n",
    "q10_part_5 VARCHAR (55), \n",
    "q10_part_6 VARCHAR (55), \n",
    "q10_part_7 VARCHAR (55), \n",
    "q10_part_8 VARCHAR (55), \n",
    "q10_part_9 VARCHAR (55), \n",
    "q10_part_10 VARCHAR (55), \n",
    "q10_part_11 VARCHAR (55), \n",
    "q10_part_12 VARCHAR (55), \n",
    "q10_part_13 VARCHAR (55), \n",
    "q10_part_14 VARCHAR (55), \n",
    "q10_part_15 VARCHAR (55),\n",
    "q10_part_16 VARCHAR (55), \n",
    "q10_other VARCHAR (55)\n",
    "dxt482 VARCHAR (55)\n",
    ");'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos query de creacion de tablas xml.\n",
    "\n",
    "tabla_xml = '''CREATE TABLE IF NOT EXISTS data_xml (\n",
    "`index_xml` INT NOT NULL PRIMARY KEY,\n",
    "`time` INT,\n",
    "`age` VARCHAR(20),\n",
    "`gender` VARCHAR(20),\n",
    "`index_sql` INT,\n",
    "CONSTRAINT `fk_data_xml_data_sql`\n",
    "FOREIGN KEY (`index_sql`)\n",
    "REFERENCES `data_sql` (`index_sql`)\n",
    "ON DELETE CASCADE\n",
    "ON UPDATE CASCADE\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos query de creacion de tablas txt.\n",
    "\n",
    "tabla_txt = ''' CREATE TABLE IF NOT EXISTS data_txt (\n",
    "index_txt INT NOT NULL PRIMARY KEY,\n",
    "index_sql INT,\n",
    "q3 VARCHAR (50),\n",
    "q4 VARCHAR (50),\n",
    "q5 VARCHAR (50),\n",
    "q6 VARCHAR (50),\n",
    "q7 VARCHAR (50),\n",
    "q8 VARCHAR (50),\n",
    "q9 VARCHAR (50),\n",
    "q11 VARCHAR (50),\n",
    "q12 VARCHAR (50),\n",
    "q13 VARCHAR (50),\n",
    "q14 VARCHAR (50),\n",
    "q15 VARCHAR (50),\n",
    "q16 VARCHAR (50),\n",
    "q17 VARCHAR (50),\n",
    "q20 VARCHAR (50),\n",
    "q21 VARCHAR (50),\n",
    "q22 VARCHAR (50),\n",
    "q23 VARCHAR (50),\n",
    "q24 VARCHAR (50),\n",
    "q25 VARCHAR (50),\n",
    "q26 VARCHAR (50),\n",
    "q32 VARCHAR (50),\n",
    "q33 VARCHAR (50),\n",
    "q34 VARCHAR (50),\n",
    "q35 VARCHAR (50),\n",
    "q41 VARCHAR (50),\n",
    "CONSTRAINT `fk_data_txt_data_sql`\n",
    "\tFOREIGN KEY (index_sql) \n",
    "\tREFERENCES `data_sql` (index_sql)\n",
    "\tON DELETE CASCADE\n",
    "\tON UPDATE CASCADE\n",
    "    );'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corremos las funciones para que se creen cada una de las tablas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQLCursor: CREATE TABLE IF NOT EXISTS data_sql (\n",
      "in..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "creacion_tablas(tabla_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQLCursor: CREATE TABLE IF NOT EXISTS data_xml (\n",
      "`i..\n"
     ]
    }
   ],
   "source": [
    "creacion_tablas(tabla_xml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQLCursor:  CREATE TABLE IF NOT EXISTS data_txt (\n",
      "i..\n"
     ]
    }
   ],
   "source": [
    "creacion_tablas (tabla_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creada la base de datos y la tabla tenemos que insertar los valores que tenemos para cada una de ellas, se nos presenta la situacion de que los datos que contiene cada archivo no estan  listos para ser cargados, es necesario que realicemos limpieza de los mismos con distintas funciones dependiendo del tipo de archivo que tratemos, para ellos vamos a definir una clase que identifique que extencion de archivo estamos leyendo y proceda a realizarle las modificaciones necesarias para cargar sus datos en la tabla correspondiente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos librerias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import os.path\n",
    "import xml.etree.ElementTree as ET\n",
    "import mysql.connector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datos_limpios:\n",
    "\n",
    "    def __init__ (self,nombre_archivo, extension_archivo):\n",
    "\n",
    "        self.nombre_archivo = nombre_archivo\n",
    "        self.extension_archivo = extension_archivo\n",
    "\n",
    "     \n",
    "\n",
    "    def  abrir_archivos (self):\n",
    "    \n",
    "            #nombre = os.path.splitext(self)[0]#\n",
    "            #print(nombre)\n",
    "            #extension_archivo = os.path.splitext(self)[1]\n",
    "            #print(extension)\n",
    "\n",
    "            if  self.extension_archivo == '.xml':  #funciones xml para lectura ficheros.\n",
    "                \n",
    "                tree = ET.parse(self.nombre_archivo)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                self.nombre_archivo = []\n",
    "                for child in root:\n",
    "                        xml_dict = {}\n",
    "                        for subchild in child:\n",
    "                            xml_dict[subchild.tag] = subchild.text\n",
    "                        self.nombre_archivo.append(xml_dict)\n",
    "                \n",
    "                return self.nombre_archivo\n",
    "\n",
    "                      \n",
    "            elif self.extension_archivo == '.txt':  #funciones txt para lectura ficheros.\n",
    "\n",
    "                with open(self.nombre_archivo,'r') as file:\n",
    "                    self.nombre_archivo = file.readlines()\n",
    "\n",
    "                return self.nombre_archivo\n",
    "\n",
    "           \n",
    "\n",
    "            #elif extension == '.sql':\n",
    "            #funciones sql para lectura ficheros(ver que ya lo leemos directamente en sql!)\n",
    "    \n",
    "    def limpieza_datos (self,lista_lectura, extension_archivo):\n",
    "\n",
    "           \n",
    "            #nombre = os.path.splitext(self)[0]\n",
    "            #extension = os.path.splitext(self)[1]\n",
    "\n",
    "        if self.extension_archivo == '.xml':\n",
    "               \n",
    "            #def limpieza_datos (self):\n",
    "        #nombre = os.path.splitext(self)[0]\n",
    "        #extension = os.path.splitext(self)[1]\n",
    "                for dictionary in self.nombre_archivo:\n",
    "                    if dictionary.get('gender') == '0':\n",
    "                        dictionary['gender'] = 'Man'\n",
    "                    elif dictionary.get('gender') == '1':\n",
    "                        dictionary['gender'] = 'Woman'\n",
    "                    elif dictionary.get('gender') == '2':\n",
    "                        dictionary['gender'] = 'Nonbinary'\n",
    "                    elif dictionary.get('gender') == '3':\n",
    "                        dictionary['gender'] = 'Prefer not to say'\n",
    "                    elif dictionary.get('gender') == '4':\n",
    "                        dictionary['gender'] = 'Prefer to self-describe'\n",
    "                    else:    \n",
    "                        print(f\"There is an error, the unlisted values is : {dictionary.get('gender')}\")\n",
    "            \n",
    "                lista_tupla_xml= []\n",
    "                for i in self.nombre_archivo:\n",
    "                    lista_tupla_xml.append(tuple(i.values()))\n",
    "\n",
    "                return lista_tupla_xml\n",
    "   \n",
    "            \n",
    "        elif self.extension_archivo == '.txt':\n",
    "                \n",
    "                lista_puntocoma = []\n",
    "                lista_espacios = []\n",
    "                lista_under = []  \n",
    "                lista_final = []  \n",
    "                lista_tupla = []\n",
    "                lista_tupla_txt = []\n",
    "\n",
    "            #def limpieza_txt (self): # Vamos a quitar los puntos y comas de la lista y convertir cada string en lista.\n",
    "                for i in self.nombre_archivo:\n",
    "            \n",
    "                    lista_intermedia = i.split(\";\")\n",
    "                    lista_puntocoma.append(lista_intermedia)\n",
    "\n",
    "            #def espacios(self):# Vamos a quitar los espacios de mas en cada string.\n",
    "                for sublista in lista_puntocoma[1:]:\n",
    "\n",
    "                    lista_almancenado_strings = []\n",
    "\n",
    "                    for palabra in sublista:\n",
    "                        palabra = palabra.strip()\n",
    "                        lista_almancenado_strings.append(palabra)\n",
    "                \n",
    "                    lista_espacios.append(lista_almancenado_strings)\n",
    "\n",
    "             #def under(self):\n",
    "                for sublista in lista_espacios[:]:\n",
    "                    \n",
    "                    lista_almancenado_under = []\n",
    "\n",
    "                    for palabra in sublista:\n",
    "                        i = palabra.replace('<','under')\n",
    "                        lista_almancenado_under.append(i)\n",
    "        \n",
    "                    lista_under.append(lista_almancenado_under)\n",
    "\n",
    "            #def null(self):\n",
    "                for sublista in lista_under[:]:\n",
    "\n",
    "                    lista_almancenado_null = []\n",
    "                    for palabra in sublista:\n",
    "                        x = palabra.replace('null','NULL')\n",
    "                        lista_almancenado_null.append(x)\n",
    "    \n",
    "                    lista_final.append(lista_almancenado_null)\n",
    "\n",
    "                for z in lista_final:\n",
    "                    lista_tupla = tuple(z) \n",
    "                    lista_tupla_txt.append(lista_tupla)   \n",
    "\n",
    "                return lista_tupla_txt\n",
    "          \n",
    "            #elif extension == '.sql':\n",
    "\n",
    "\n",
    "            #funciones sql limpieza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos cada una de las clases por cada extension de archivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_class = Datos_limpios('data_xml.xml', '.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_class = Datos_limpios('data_txt.txt', '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_class = Datos_limpios('data_sql.sql', '.sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamamos a las funciones de la clase de apertura y limpieza del archivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_lista = xml_class.abrir_archivos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_limpio = xml_class.limpieza_datos(xml_lista, '.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('26', '26', '7750', '45-49', 'Man'),\n",
       " ('27', '27', '607', '22-24', 'Man'),\n",
       " ('28', '28', '525', '22-24', 'Woman'),\n",
       " ('29', '29', '501', '18-21', 'Man'),\n",
       " ('30', '30', '415', '22-24', 'Man'),\n",
       " ('31', '31', '317', '30-34', 'Man'),\n",
       " ('32', '32', '171', '22-24', 'Nonbinary'),\n",
       " ('33', '33', '744', '30-34', 'Woman'),\n",
       " ('34', '34', '668', '22-24', 'Man'),\n",
       " ('35', '35', '460', '30-34', 'Woman'),\n",
       " ('36', '36', '244', '25-29', 'Woman'),\n",
       " ('37', '37', '901', '30-34', 'Man'),\n",
       " ('38', '38', '625', '22-24', 'Man'),\n",
       " ('39', '39', '1239', '18-21', 'Man'),\n",
       " ('40', '40', '229993', '25-29', 'Man'),\n",
       " ('41', '41', '312', '25-29', 'Man'),\n",
       " ('42', '42', '976', '55-59', 'Man'),\n",
       " ('43', '43', '1890', '30-34', 'Woman'),\n",
       " ('44', '44', '357', '18-21', 'Man'),\n",
       " ('45', '45', '660', '40-44', 'Man'),\n",
       " ('46', '46', '1524', '22-24', 'Man'),\n",
       " ('47', '47', '453', '18-21', 'Woman'),\n",
       " ('48', '48', '793', '25-29', 'Man'),\n",
       " ('49', '49', '557', '30-34', 'Woman'),\n",
       " ('50', '50', '5215', '25-29', 'Man')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_limpio [25:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_lista = txt_class.abrir_archivos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_limpio = txt_class.limpieza_datos(txt_lista, '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Datos_limpios' object has no attribute 'lectura_archivo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/db/hp0l5_js4yv8br5y2tc3frpm0000gn/T/ipykernel_84567/235198605.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msql_lista\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlectura_archivo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Datos_limpios' object has no attribute 'lectura_archivo'"
     ]
    }
   ],
   "source": [
    "sql_lista = sql_class.lectura_archivo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sql_lista' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/db/hp0l5_js4yv8br5y2tc3frpm0000gn/T/ipykernel_84567/3640829731.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msql_limpio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimpieza_datos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_lista\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sql_lista' is not defined"
     ]
    }
   ],
   "source": [
    "sql_limpio = sql_class.limpieza_datos(sql_lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez limpios los datos necesitamos extraer los valores de cada archivo en una query para poder asi cargarlos en las tablas respectivas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_val_xml = xml_limpio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_val_txt = txt_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sql_limpio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/db/hp0l5_js4yv8br5y2tc3frpm0000gn/T/ipykernel_84567/2518437616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_val_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql_limpio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sql_limpio' is not defined"
     ]
    }
   ],
   "source": [
    "query_val_sql = sql_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1', '1', '784', '50-54', 'Man')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_limpio[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la carga de datos necesitamos tener los nombres de columnas de cada una de las tablas, por lo que creamos la query para cada una de las tablas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sql_xml = '''INSERT INTO data_xml (index_xml, time, age, gender,index_sql) VALUES (%s, %s,%s, %s, %s)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sql_txt ='''INSERT INTO data_txt (index_txt, index_sql, q3, q4, q5, q6, q7, q8, q9, q11, q12, q13, q14, q15, q16, q17, q20, q21, q22, q23, q24, q25, q26, q32, q33, q34, q35, q41)VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sql_sql = '''INSERT INTO data_sql (`index_sql`,`q10_part_1`,`q10_part_2`,`q10_part_3`, `q10_part_4`, `q10_part_5`, `q10_part_6`,`q10_part_7`, `q10_part_8`,`q10_part_9`,`q10_part_10`, `q10_part_11`, `q10_part_12`, `q10_part_13`, `q10_part_14`, `q10_part_15`, `q10_part_16`, `q10_other`)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Insertamos datos en las tablas #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertar_datos (query_sql,query_values):\n",
    "\n",
    "  cnx = mysql.connector.connect(user='root', password='AlumnaAdalab',\n",
    "                              host='127.0.0.1', database='Project_1')\n",
    "\n",
    "\n",
    "  mycursor = cnx.cursor()\n",
    "  #sql = query_sql\n",
    "  #val = query_values\n",
    "  \n",
    "  try: \n",
    "      mycursor.execute('SET FOREING_KEY_CHECKS = 0')\n",
    "      mycursor.executemany(query_sql, query_values)\n",
    "      cnx.commit()\n",
    "      print(mycursor.rowcount, \"registro/s insertado/s.\")\n",
    "      mycursor.execute('SET FOREING_KEY_CHECKS = 1')\n",
    "\n",
    "  except mysql.connector.Error as err:\n",
    "      print(err)\n",
    "      print(\"Error Code:\", err.errno)\n",
    "      print(\"SQLSTATE\", err.sqlstate)\n",
    "      print(\"Message\", err.msg)\n",
    "    \n",
    "  else:\n",
    "      mycursor.close()\n",
    "      cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193 (HY000): Unknown system variable 'FOREING_KEY_CHECKS'\n",
      "Error Code: 1193\n",
      "SQLSTATE HY000\n",
      "Message Unknown system variable 'FOREING_KEY_CHECKS'\n"
     ]
    }
   ],
   "source": [
    "insertar_datos(query_sql_xml, query_val_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough parameters for the SQL statement\n",
      "Error Code: -1\n",
      "SQLSTATE None\n",
      "Message Not enough parameters for the SQL statement\n"
     ]
    }
   ],
   "source": [
    "insertar_datos(query_sql_txt, query_val_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertar_datos(query_sql_sql, query_val_sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a52af493819045717511545598ab2b73dabca4ca61b402315e0ef2b43666342d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
