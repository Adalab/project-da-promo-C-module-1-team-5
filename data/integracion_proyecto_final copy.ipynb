{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos Base de datos #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQLCursor: CREATE DATABASE IF NOT EXISTS Project_1\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "cnx = mysql.connector.connect(user='root', password='AlumnaAdalab',\n",
    "                              host='127.0.0.1')\n",
    "\n",
    "\n",
    "mycursor = cnx.cursor()\n",
    "try:\n",
    "    mycursor.execute(\"CREATE DATABASE IF NOT EXISTS Project_1\")\n",
    "    print(mycursor)\n",
    "except mysql.connector.Error as err:\n",
    "    print(err)\n",
    "    print(\"Error Code:\", err.errno)\n",
    "    print(\"SQLSTATE\", err.sqlstate)\n",
    "    print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos tablas #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Creamos una funcion para crear la tabla correspondiente a cada extension de archivo, dentro de la Base de Datos Project_1\n",
    "\n",
    "def creacion_tablas (query_tablas):\n",
    "    \n",
    "    cnx = mysql.connector.connect(user='root', password='AlumnaAdalab',\n",
    "                              host='127.0.0.1', database='Project_1')\n",
    "\n",
    "\n",
    "    mycursor = cnx.cursor()\n",
    "    try:\n",
    "        mycursor.execute(query_tablas)\n",
    "        cnx.commit()\n",
    "        print(mycursor)\n",
    "    \n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "        print(\"Error Code:\", err.errno)\n",
    "        print(\"SQLSTATE\", err.sqlstate)\n",
    "        print(\"Message\", err.msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos query de creacion de tablas sql:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_sql = ('''CREATE TABLE IF NOT EXISTS data_sql (\n",
    "index_sql INT NOT NULL PRIMARY KEY , \n",
    "q10_part_1 VARCHAR (55), \n",
    "q10_part_2 VARCHAR (55), \n",
    "q10_part_3 VARCHAR (55), \n",
    "q10_part_4 VARCHAR (55), \n",
    "q10_part_5 VARCHAR (55), \n",
    "q10_part_6 VARCHAR (55), \n",
    "q10_part_7 VARCHAR (55), \n",
    "q10_part_8 VARCHAR (55), \n",
    "q10_part_9 VARCHAR (55), \n",
    "q10_part_10 VARCHAR (55), \n",
    "q10_part_11 VARCHAR (55), \n",
    "q10_part_12 VARCHAR (55), \n",
    "q10_part_13 VARCHAR (55), \n",
    "q10_part_14 VARCHAR (55), \n",
    "q10_part_15 VARCHAR (55),\n",
    "q10_part_16 VARCHAR (55), \n",
    "q10_other VARCHAR (55)\n",
    ");''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_xml = ('''CREATE TABLE IF NOT EXISTS data_xml (\n",
    "`level_0` INT,\n",
    "`index_xml` INT NOT NULL PRIMARY KEY,\n",
    "`time` TEXT (50),\n",
    "`age` TEXT (50),\n",
    "`gender` TEXT (50),\n",
    "`index_sql` INT,\n",
    "CONSTRAINT `fk_data_xml_data_sql`\n",
    "FOREIGN KEY (`index_sql`)\n",
    "REFERENCES `data_sql` (`index_sql`)\n",
    "ON DELETE CASCADE\n",
    "ON UPDATE CASCADE\n",
    ")''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_txt = (''' CREATE TABLE IF NOT EXISTS data_txt (\n",
    "index_txt INT AUTO_INCREMENT NOT NULL PRIMARY KEY,\n",
    "index_sql INT,\n",
    "q3 TEXT(300),\n",
    "q4 TEXT(300),\n",
    "q5 TEXT(300),\n",
    "q6 TEXT(300),\n",
    "q7 TEXT(300),\n",
    "q8 TEXT(300),\n",
    "q9 TEXT(300),\n",
    "q11 TEXT(300),\n",
    "q12 TEXT(300),\n",
    "q13 TEXT(300),\n",
    "q14 TEXT(300),\n",
    "q15 TEXT(300),\n",
    "q16 TEXT(300),\n",
    "q17 TEXT(300),\n",
    "q20 TEXT(300),\n",
    "q21 TEXT(300),\n",
    "q22 TEXT(300),\n",
    "q23 TEXT(300),\n",
    "q24 TEXT(300),\n",
    "q25 TEXT(300),\n",
    "q26 TEXT(300),\n",
    "q32 TEXT(300),\n",
    "q33 TEXT(300),\n",
    "q34 TEXT(300),\n",
    "q35 TEXT(300),\n",
    "q41 TEXT(300),\n",
    "CONSTRAINT `fk_data_txt_data_sql`\n",
    "    FOREIGN KEY (index_sql)\n",
    "    REFERENCES `data_sql` (index_sql)\n",
    "    ON DELETE CASCADE\n",
    "    ON UPDATE CASCADE\n",
    "    );''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corremos las funciones para que se creen cada una de las tablas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQLCursor: CREATE TABLE IF NOT EXISTS data_sql (\n",
      "in..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "creacion_tablas(tabla_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQLCursor: CREATE TABLE IF NOT EXISTS data_xml (\n",
      "`i..\n"
     ]
    }
   ],
   "source": [
    "creacion_tablas(tabla_xml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQLCursor:  CREATE TABLE IF NOT EXISTS data_txt (\n",
      "i..\n"
     ]
    }
   ],
   "source": [
    "creacion_tablas (tabla_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creada la base de datos y la tabla tenemos que insertar los valores que tenemos para cada una de ellas, se nos presenta la situacion de que los datos que contiene cada archivo no estan  listos para ser cargados, es necesario que realicemos limpieza de los mismos con distintas funciones dependiendo del tipo de archivo que tratemos, para ellos vamos a definir una clase que identifique que extencion de archivo estamos leyendo y proceda a realizarle las modificaciones necesarias para cargar sus datos en la tabla correspondiente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos librerias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import os.path\n",
    "import xml.etree.ElementTree as ET\n",
    "import mysql.connector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datos_limpios:\n",
    "\n",
    "    def __init__ (self,nombre_archivo, extension_archivo):\n",
    "\n",
    "        self.nombre_archivo = nombre_archivo\n",
    "        self.extension_archivo = extension_archivo\n",
    "\n",
    "     \n",
    "\n",
    "    def  abrir_archivos (self):\n",
    "    \n",
    "            #nombre = os.path.splitext(self)[0]#\n",
    "            #print(nombre)\n",
    "            #extension_archivo = os.path.splitext(self)[1]\n",
    "            #print(extension)\n",
    "\n",
    "            if  self.extension_archivo == '.xml':  #funciones xml para lectura ficheros.\n",
    "                \n",
    "                tree = ET.parse(self.nombre_archivo)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                self.nombre_archivo = []\n",
    "                for child in root:\n",
    "                        xml_dict = {}\n",
    "                        for subchild in child:\n",
    "                            xml_dict[subchild.tag] = subchild.text\n",
    "                        self.nombre_archivo.append(xml_dict)\n",
    "                \n",
    "                return self.nombre_archivo\n",
    "\n",
    "                      \n",
    "            elif self.extension_archivo == '.txt':  #funciones txt para lectura ficheros.\n",
    "\n",
    "                with open(self.nombre_archivo,'r') as file:\n",
    "                    self.nombre_archivo = file.readlines()\n",
    "\n",
    "                return self.nombre_archivo\n",
    "\n",
    "           \n",
    "\n",
    "            #elif extension == '.sql':\n",
    "            #funciones sql para lectura ficheros(ver que ya lo leemos directamente en sql!)\n",
    "    \n",
    "    def limpieza_datos (self,lista_lectura, extension_archivo):\n",
    "\n",
    "           \n",
    "            #nombre = os.path.splitext(self)[0]\n",
    "            #extension = os.path.splitext(self)[1]\n",
    "\n",
    "        if self.extension_archivo == '.xml':\n",
    "               \n",
    "            #def limpieza_datos (self):\n",
    "        #nombre = os.path.splitext(self)[0]\n",
    "        #extension = os.path.splitext(self)[1]\n",
    "                for dictionary in self.nombre_archivo:\n",
    "                    if dictionary.get('gender') == '0':\n",
    "                        dictionary['gender'] = 'Man'\n",
    "                    elif dictionary.get('gender') == '1':\n",
    "                        dictionary['gender'] = 'Woman'\n",
    "                    elif dictionary.get('gender') == '2':\n",
    "                        dictionary['gender'] = 'Nonbinary'\n",
    "                    elif dictionary.get('gender') == '3':\n",
    "                        dictionary['gender'] = 'Prefer not to say'\n",
    "                    elif dictionary.get('gender') == '4':\n",
    "                        dictionary['gender'] = 'Prefer to self-describe'\n",
    "                    else:    \n",
    "                        print(f\"There is an error, the unlisted values is : {dictionary.get('gender')}\")\n",
    "\n",
    "                    #dictionary.pop(\"level_0\")\n",
    "            \n",
    "                lista_tupla_xml= []\n",
    "                for i in self.nombre_archivo:\n",
    "                    lista_tupla_xml.append(tuple(i.values()))\n",
    "\n",
    "                return lista_tupla_xml\n",
    "   \n",
    "            \n",
    "        elif self.extension_archivo == '.txt':\n",
    "                \n",
    "                lista_puntocoma = []\n",
    "                lista_espacios = []\n",
    "                lista_under = []  \n",
    "                lista_final = []  \n",
    "                lista_tupla = []\n",
    "                lista_tupla_txt = []\n",
    "\n",
    "            #def limpieza_txt (self): # Vamos a quitar los puntos y comas de la lista y convertir cada string en lista.\n",
    "                for i in self.nombre_archivo:\n",
    "            \n",
    "                    lista_intermedia = i.split(\";\")\n",
    "                    lista_puntocoma.append(lista_intermedia)\n",
    "\n",
    "            #def espacios(self):# Vamos a quitar los espacios de mas en cada string.\n",
    "                for sublista in lista_puntocoma[1:]:\n",
    "\n",
    "                    lista_almancenado_strings = []\n",
    "\n",
    "                    for palabra in sublista:\n",
    "                        palabra = palabra.strip()\n",
    "                        lista_almancenado_strings.append(palabra)\n",
    "                \n",
    "                    lista_espacios.append(lista_almancenado_strings)\n",
    "\n",
    "             #def under(self):\n",
    "                for sublista in lista_espacios[:]:\n",
    "                    \n",
    "                    lista_almancenado_under = []\n",
    "\n",
    "                    for palabra in sublista:\n",
    "                        i = palabra.replace('<','under')\n",
    "                        lista_almancenado_under.append(i)\n",
    "        \n",
    "                    lista_under.append(lista_almancenado_under)\n",
    "\n",
    "            #def null(self):\n",
    "                for sublista in lista_under[:]:\n",
    "\n",
    "                    lista_almancenado_null = []\n",
    "                    for palabra in sublista:\n",
    "                        x = palabra.replace('null','NULL')\n",
    "                        lista_almancenado_null.append(x)\n",
    "    \n",
    "                    lista_final.append(lista_almancenado_null)\n",
    "\n",
    "                for z in lista_final:\n",
    "                    lista_tupla = tuple(z) \n",
    "                    lista_tupla_txt.append(lista_tupla)   \n",
    "\n",
    "                return lista_tupla_txt\n",
    "          \n",
    "            #elif extension == '.sql':\n",
    "\n",
    "\n",
    "            #funciones sql limpieza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos cada una de las clases por cada extension de archivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_class = Datos_limpios('data_xml.xml', '.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_class = Datos_limpios('data_txt.txt', '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_class = Datos_limpios('data_sql.sql', '.sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamamos a las funciones de la clase de apertura y limpieza del archivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_lista = xml_class.abrir_archivos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_limpio = xml_class.limpieza_datos(xml_lista, '.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('26', '26', '7750', '45-49', 'Man'),\n",
       " ('27', '27', '607', '22-24', 'Man'),\n",
       " ('28', '28', '525', '22-24', 'Woman'),\n",
       " ('29', '29', '501', '18-21', 'Man'),\n",
       " ('30', '30', '415', '22-24', 'Man'),\n",
       " ('31', '31', '317', '30-34', 'Man'),\n",
       " ('32', '32', '171', '22-24', 'Nonbinary'),\n",
       " ('33', '33', '744', '30-34', 'Woman'),\n",
       " ('34', '34', '668', '22-24', 'Man'),\n",
       " ('35', '35', '460', '30-34', 'Woman'),\n",
       " ('36', '36', '244', '25-29', 'Woman'),\n",
       " ('37', '37', '901', '30-34', 'Man'),\n",
       " ('38', '38', '625', '22-24', 'Man'),\n",
       " ('39', '39', '1239', '18-21', 'Man'),\n",
       " ('40', '40', '229993', '25-29', 'Man'),\n",
       " ('41', '41', '312', '25-29', 'Man'),\n",
       " ('42', '42', '976', '55-59', 'Man'),\n",
       " ('43', '43', '1890', '30-34', 'Woman'),\n",
       " ('44', '44', '357', '18-21', 'Man'),\n",
       " ('45', '45', '660', '40-44', 'Man'),\n",
       " ('46', '46', '1524', '22-24', 'Man'),\n",
       " ('47', '47', '453', '18-21', 'Woman'),\n",
       " ('48', '48', '793', '25-29', 'Man'),\n",
       " ('49', '49', '557', '30-34', 'Woman'),\n",
       " ('50', '50', '5215', '25-29', 'Man')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_limpio [25:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_lista = txt_class.abrir_archivos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_limpio = txt_class.limpieza_datos(txt_lista, '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql_lista = sql_class.lectura_archivo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql_limpio = sql_class.limpieza_datos(sql_lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez limpios los datos necesitamos extraer los valores de cada archivo en una query para poder asi cargarlos en las tablas respectivas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_val_xml = xml_limpio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_val_txt = txt_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uery_val_sql = sql_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1', '1', '784', '50-54', 'Man')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_limpio[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la carga de datos necesitamos tener los nombres de columnas de cada una de las tablas, por lo que creamos la query para cada una de las tablas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sql_xml = '''INSERT INTO data_xml (index_xml,index_sql, time, age, gender) VALUES (%s, %s,%s, %s,%s)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sql_txt ='''INSERT INTO data_txt ( index_sql, q3, q4, q5, q6, q7, q8, q9, q11, q12, q13, q14, q15, q16, q17, q20, q21, q22, q23, q24, q25, q26, q32, q33, q34, q35, q41)VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sql_sql = '''INSERT INTO data_sql (`index_sql`,`q10_part_1`,`q10_part_2`,`q10_part_3`, `q10_part_4`, `q10_part_5`, `q10_part_6`,`q10_part_7`, `q10_part_8`,`q10_part_9`,`q10_part_10`, `q10_part_11`, `q10_part_12`, `q10_part_13`, `q10_part_14`, `q10_part_15`, `q10_part_16`, `q10_other`)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Insertamos datos en las tablas #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertar_datos (query_sql,query_values):\n",
    "\n",
    "  cnx = mysql.connector.connect(user='root', password='AlumnaAdalab',\n",
    "                              host='127.0.0.1', database='Project_1')\n",
    "\n",
    "\n",
    "  mycursor = cnx.cursor()\n",
    "  #sql = query_sql\n",
    "  #val = query_values\n",
    "  \n",
    "  try: \n",
    "      #mycursor.execute('SET FOREING_KEY_CHECKS = 0')\n",
    "      mycursor.executemany(query_sql, query_values)\n",
    "      cnx.commit()\n",
    "      print(mycursor.rowcount, \"registro/s insertado/s.\")\n",
    "      #mycursor.execute('SET FOREING_KEY_CHECKS = 1')\n",
    "\n",
    "  except mysql.connector.Error as err:\n",
    "      print(err)\n",
    "      print(\"Error Code:\", err.errno)\n",
    "      print(\"SQLSTATE\", err.sqlstate)\n",
    "      print(\"Message\", err.msg)\n",
    "    \n",
    "  else:\n",
    "      mycursor.close()\n",
    "      cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1062 (23000): Duplicate entry '1' for key 'data_xml.PRIMARY'\n",
      "Error Code: 1062\n",
      "SQLSTATE 23000\n",
      "Message Duplicate entry '1' for key 'data_xml.PRIMARY'\n"
     ]
    }
   ],
   "source": [
    "insertar_datos(query_sql_xml, query_val_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25972 registro/s insertado/s.\n"
     ]
    }
   ],
   "source": [
    "insertar_datos(query_sql_txt, query_val_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_val_sql' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [139], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m insertar_datos(query_sql_sql, query_val_sql)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'query_val_sql' is not defined"
     ]
    }
   ],
   "source": [
    "insertar_datos(query_sql_sql, query_val_sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db5cedc7e114859ad608ddd0e9acad792dd59d9153581ae5b253a51e1afe4cda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
